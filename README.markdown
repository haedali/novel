# âœ¨ Agentic Unfiltered Storytelling AI: Build Worlds, Characters & Infinite Narratives

Unfiltered Story Generator is an **agentic AI-powered storytelling platform** that empowers users to create unrestricted stories, novels, or sequels step by step â€” starting from a simple story idea. Built using **Mistral LLM (via Ollama)** and **Streamlit**, it generates imaginative worlds, characters, and plotlines, then allows story continuation through a built-in chat interface. 

Unlike conventional AI tools with heavy safety filters, this project offers **true creative freedom** for writers, game designers, or narrative researchers â€” while remaining modular and lightweight for local development.

---

## ğŸ” Features

- **ğŸ§  Unrestricted Story Generation** using open-source LLMs like Mistral and TinyLLaMA.
- **ğŸ‘ï¸ Step-by-Step Pipeline**: Story Idea â†’ World Creation â†’ Characters â†’ Full Story.
- **ğŸ’¬ Sequel Chat Interface**: Continue the story as an evolving dialogue.
- **ğŸ“¦ Local-first, Open Design**: No cloud APIs or censorship filters.
- **ğŸ“¸ Screenshots Output** for each stage of the generation process.

---

## âš™ï¸ Tech Stack

| Layer              | Tool / Library                     |
|--------------------|------------------------------------|
| ğŸ’¡ LLM Backend      | [Ollama](https://ollama.com/) with `mistral:instruct` or `tinyllama` |
| ğŸ§  Prompt Chaining  | [LangChain](https://www.langchain.com/) |
| ğŸŒ Frontend         | [Streamlit](https://streamlit.io/) |
| ğŸ’¾ Local Runtime    | Python 3.10+ with virtual environment |
| ğŸ§° Dev Environment  | Visual Studio Code (recommended)  |

---

## ğŸ“· Output Screenshots

| Description           | Preview |
|-----------------------|---------|
| ğŸŒ World Description  | ![](screenshots/world_description.png) |
| ğŸ‘¤ Character Design   | ![](screenshots/character_description.png) |
| ğŸ“– Generated Story    | ![](screenshots/generated_story.png) |
| â• Sequel Generator   | ![](screenshots/sequel_generator.png) |
| ğŸ§¾ Full Tracker View  | ![](screenshots/full_story_tracker.png) |
| ğŸ  Home Page          | ![](screenshots/home_page.png) |

---

## ğŸ› ï¸ Installation & Setup

### 1. Clone the repository
```bash
git clone https://github.com/your-username/unfiltered_story_gen.git
cd unfiltered_story_gen
```

### 2. Set up a virtual environment
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

### 4. Pull a model with Ollama
Choose based on your PC specs:

**ğŸ’ª For better output (requires ~6â€“8GB RAM):**
```bash
ollama pull mistral:instruct
```

**ğŸ–¥ï¸ For low-end machines (works on 4GB RAM):**
```bash
ollama pull tinyllama
```

Update your backend file accordingly:

```python
# backend/llm_engine.py
llm = Ollama(model="tinyllama")  # or "mistral:instruct"
```

### 5. Run the app
```bash
streamlit run app.py
```

---

## ğŸš€ Use Cases
- âœï¸ Writers looking for AI-enhanced creativity
- ğŸ® Game developers needing lore & character backstories
- ğŸ“š Novelists experimenting with AI-first storytelling
- ğŸ§ª AI researchers studying unfiltered agentic generation

---

## ğŸ§  Why Is This Unique?
- **No Censorship Filters**: Unlike OpenAI or Gemini, this app uses open-source LLMs without built-in restrictions.
- **Agentic Control**: The system routes through prompt chaining steps with conditional logic.
- **Modular & Extendable**: Each part (world, characters, continuation) is a separate chain for easy control.
- **Runs Offline**: With Ollama, no external APIs or internet are needed after setup.
- **Lightweight Mode**: TinyLLaMA support makes it suitable for older or low-RAM systems.

---

## ğŸ“Œ Folder Structure
```
unfiltered_story_gen/
â”‚
â”œâ”€â”€ app.py                    # Streamlit UI
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ llm_engine.py         # Model connector (Ollama)
â”‚   â””â”€â”€ chains.py             # Prompt chaining logic
â””â”€â”€ screenshots/              # Generated screenshots
```

---

## â¤ï¸ Credits
- Mistral for their open-weight LLMs
- Ollama for easy local LLM integration
- Streamlit for the web UI
- LangChain for building chainable logic

---

## ğŸ“„ License
This project is open-source and licensed under the MIT License.

---

## ğŸš§ Future Improvements
- Add user login & story history saving
- Enable voice-based story prompting
- Add image generation (Stable Diffusion) for characters & scenes